# Recurrent-Neural-Network
A simple demo will be posted here before the end of July 2019.
Vanilla RNN example on the MNIST dataset using a 1-1 RNN model with one timestep.

## (BELOW IS ALL A WORK IN PROGRESS --- currently)
Recurrent Neural Network:
![Recurrent Neural Network1][RNN1]

[RNN1]: https://github.com/TensorFlow-ML-Architectures/Recurrent-Neural-Network/raw/master/architecture-rnn.png "Recurrent Neural Network"

RNN Cell Architecture:
![Recurrent Neural Network2][RNN2]

[RNN2]: https://github.com/TensorFlow-ML-Architectures/Recurrent-Neural-Network/raw/master/description-block-rnn.png "RNN Cell Architecture"

One-to-One RNN:
![Recurrent Neural Network3][RNN3]

[RNN3]: https://github.com/TensorFlow-ML-Architectures/Recurrent-Neural-Network/raw/master/rnn-one-to-one.png "One-to-One RNN"

Confusion Matrix:
![Confusion Matrix1][CM1]

[CM1]: https://github.com/TensorFlow-ML-Architectures/Recurrent-Neural-Network/raw/master/rnn_model_1/plot.png "Confusion Matrix"

Accuracy Plot (Orange: Training data, Blue: Testing data):
![Accuracy Plot1][AP1]

[AP1]: https://github.com/TensorFlow-ML-Architectures/Recurrent-Neural-Network/raw/master/rnn_model_1/acc.png "Accuracy Plot"

Loss Plot (Orange: Training data, Blue: Testing data):
![Loss Plot1][LP1]

[LP1]: https://github.com/TensorFlow-ML-Architectures/Recurrent-Neural-Network/raw/master/rnn_model_1/loss.png "Loss Plot"

## Extras
* Dropout
* Regularization
* Other weight initializations

Confusion Matrix (w/ Extra Configurations):
![Confusion Matrix2][CM2]

[CM2]: NO_LINK_YET "Confusion Matrix"

Accuracy Plot (w/ Extra Configurations) (Orange: Training data, Blue: Testing data):
![Accuracy Plot2][AP2]

[AP2]: NO_LINK_YET "Accuracy Plot"

Loss Plot (w/ Extra Configurations) (Orange: Training data, Blue: Testing data):
![Loss Plot2][LP2]

[LP2]: NO_LINK_YET "Loss Plot"

